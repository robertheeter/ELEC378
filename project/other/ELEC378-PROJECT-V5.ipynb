{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee42dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROBERT HEETER\n",
    "# ELEC 378 Machine Learning\n",
    "# 29 April 2023\n",
    "\n",
    "# PROJECT V5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f49467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab438b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "for n_mfcc in [31,32,33,34,35,36,37,38,39,40,41,42]:\n",
    "    \n",
    "    directory = os.path.join(os.getcwd(),'elec-378-sp2023-speech-emotion-classification/data/data/')\n",
    "    data = np.empty((1125, 2), dtype=object)\n",
    "\n",
    "    emotion_to_id = {\n",
    "        \"angry\" : 0,\n",
    "        \"calm\" : 1,\n",
    "        \"disgust\" : 2,\n",
    "        \"fearful\" : 3,\n",
    "        \"happy\" : 4,\n",
    "        \"neutral\" : 5,\n",
    "        \"sad\" : 6,\n",
    "        \"surprised\" : 7\n",
    "    }\n",
    "\n",
    "    i = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "\n",
    "        if os.path.isfile(f):\n",
    "            emotion = filename[:len(filename)-7]\n",
    "            data[i][0] = \"/\"+filename\n",
    "            data[i][1] = int(emotion_to_id[emotion])\n",
    "            i += 1\n",
    "\n",
    "    def make_mfcc(file, n_mfcc):\n",
    "        sig, sr = librosa.load(file)\n",
    "        sig_mfcc = librosa.feature.mfcc(y=sig, sr=sr, n_mfcc=n_mfcc, S=None, htk=True)\n",
    "        sig_mfcc_avg = np.mean(sig_mfcc, axis=1)\n",
    "\n",
    "        return sig_mfcc_avg\n",
    "\n",
    "    n_mfcc = n_mfcc\n",
    "\n",
    "    X = np.empty((len(data), n_mfcc), dtype=float)\n",
    "    y = np.empty((len(data)), dtype=int)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        file = directory + data[i][0]\n",
    "        X[i] = make_mfcc(file, n_mfcc=n_mfcc)\n",
    "        y[i] = data[i][1]\n",
    "\n",
    "    #     print(X, y)\n",
    "\n",
    "    for c in [10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32]:\n",
    "        avg_acc = 0\n",
    "        for trial in range(40):\n",
    "\n",
    "            from sklearn.model_selection import train_test_split\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            from sklearn.pipeline import make_pipeline\n",
    "            from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "            from sklearn.svm import SVC\n",
    "            from sklearn.metrics import accuracy_score\n",
    "\n",
    "            clf = make_pipeline(RobustScaler(), SVC(C=c, tol=0.001))\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "            avg_acc += accuracy\n",
    "\n",
    "        avg_acc = avg_acc/40\n",
    "        accs.append([n_mfcc,c,avg_acc])\n",
    "        print(f\"n_mfcc: {n_mfcc}, c: {c}, acc: {avg_acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427266a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6edf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(os.getcwd(),'elec-378-sp2023-speech-emotion-classification/data/data/')\n",
    "data = np.empty((1125, 2), dtype=object)\n",
    "\n",
    "emotion_to_id = {\n",
    "    \"angry\" : 0,\n",
    "    \"calm\" : 1,\n",
    "    \"disgust\" : 2,\n",
    "    \"fearful\" : 3,\n",
    "    \"happy\" : 4,\n",
    "    \"neutral\" : 5,\n",
    "    \"sad\" : 6,\n",
    "    \"surprised\" : 7\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "\n",
    "    if os.path.isfile(f):\n",
    "        emotion = filename[:len(filename)-7]\n",
    "        data[i][0] = \"/\"+filename\n",
    "        data[i][1] = int(emotion_to_id[emotion])\n",
    "        i += 1\n",
    "\n",
    "def make_mfcc(file, n_mfcc):\n",
    "    sig, sr = librosa.load(file)\n",
    "    sig_mfcc = librosa.feature.mfcc(y=sig, sr=sr, n_mfcc=n_mfcc, S=None, htk=True)\n",
    "    sig_mfcc_avg = np.mean(sig_mfcc, axis=1)\n",
    "    \n",
    "    return sig_mfcc_avg\n",
    "\n",
    "n_mfcc = 34\n",
    "n_mfcc = 40\n",
    "\n",
    "X = np.empty((len(data), n_mfcc), dtype=float)\n",
    "y = np.empty((len(data)), dtype=int)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    file = directory + data[i][0]\n",
    "    X[i] = make_mfcc(file, n_mfcc=n_mfcc)\n",
    "    y[i] = data[i][1]\n",
    "\n",
    "print(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796d01df",
   "metadata": {},
   "source": [
    "# **Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68199538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = make_pipeline(RobustScaler(), SVC(C=15, tol=0.001))\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"{accuracy*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86a5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369848a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_params = {'activation': 'relu', \n",
    "              'solver': 'lbfgs', \n",
    "              'hidden_layer_sizes': 1283, \n",
    "              'alpha': 0.3849485717707319, \n",
    "              'batch_size': 163, \n",
    "              'learning_rate': 'constant',\n",
    "              'max_iter':1000}\n",
    "\n",
    "clf = make_pipeline(RobustScaler(), MLPClassifier(**mlp_params))\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"{accuracy*100}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5529043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f2e87bf",
   "metadata": {},
   "source": [
    "# **Convolutional Neural Network (CNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# model2.add(layers.Conv2D(64, (4, 4), activation='relu', kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "# model2.add(layers.MaxPooling2D((2, 2)))# Hidden Layer 2\n",
    "# model2.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(l=0.01)))\n",
    "# model2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# model3.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', input_shape=(96, 96, 3)))\n",
    "\n",
    "# random.seed(123) # Establish Consistency in resultsmodel4 = Sequential() # Instantiate the 4th Modelmodel4.add(layers.Conv2D(32, (3, 3), activation=’relu’, input_shape=(96, 96, 3)))\n",
    "# model4.add(layers.MaxPooling2D((2, 2)))\n",
    "# model4.add(Dropout(0.4))\n",
    "# model4.add(layers.Conv2D(64, (4, 4), activation='relu'))\n",
    "# model4.add(layers.MaxPooling2D((2, 2)))\n",
    "# model4.add(Dropout(0.4)) # Flattening- Convert 2D matrix to a 1D vector\n",
    "# model4.add(layers.Flatten())\n",
    "# model4.add(layers.Dense(512, activation = 'relu'))\n",
    "# model4.add(Dropout(0.2))\n",
    "# model4.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model5.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_constraint=unit_norm(), input_shape=(96, 96, 3)))\n",
    "\n",
    "\n",
    "# model.add(Conv1D(128, 16, padding='same', input_shape=(40,1)))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Conv1D(128, 16, padding='same', input_shape=(40,1)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# # model.add(Dropout(0.4))\n",
    "\n",
    "# model.add(MaxPooling1D(pool_size=8))\n",
    "\n",
    "# model.add(Conv1D(128, 16, padding='same', input_shape=(40,1)))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Conv1D(128, 16, padding='same', input_shape=(40,1)))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Conv1D(128, 16, padding='same', input_shape=(40,1)))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# # model.add(Conv1D(128, 16, padding='same', input_shape=(40,1)))\n",
    "# # model.add(BatchNormalization())\n",
    "# # model.add(Activation('relu'))\n",
    "\n",
    "# # model.add(MaxPooling1D(pool_size=5))\n",
    "\n",
    "# # model.add(Conv1D(128, 5, padding='same', input_shape=(40,1)))\n",
    "# # model.add(Activation('relu'))\n",
    "\n",
    "# # model.add(Conv1D(128, 5, padding='same', input_shape=(40,1)))\n",
    "# # model.add(Activation('relu'))\n",
    "\n",
    "# # model.add(Dropout(0.2))\n",
    "# model.add(Flatten())\n",
    "# # model.add(Dense(10, kernel_regularizer='l2', bias_regularizer='l2'))\n",
    "# model.add(Dense(8))\n",
    "# # model.add(Activation('softmax'))\n",
    "\n",
    "# opt = keras.optimizers.RMSprop(learning_rate=0.0001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 5, padding='same', input_shape=(40,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5, padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0005, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model.add(Conv1D(128, 5,padding='same', input_shape=(34,1)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(MaxPooling1D(pool_size=(8)))\n",
    "# model.add(Conv1D(128, 5,padding='same',))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(10))\n",
    "# model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc09c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = np.expand_dims(X_train, axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "# print(X_train_cnn.shape)\n",
    "# print(X_test_cnn.shape)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "\n",
    "cnnhistory = model.fit(X_train_cnn, y_train, batch_size=4, epochs=60, validation_data=(X_test_cnn, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cnnhistory.history['accuracy'])\n",
    "plt.plot(cnnhistory.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725a1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaffd061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342f611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca275fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_cnn, y_test)\n",
    "print(f\"{accuracy*100}%\")\n",
    "\n",
    "y_pred = model.predict(X_test_cnn)\n",
    "print(np.shape(y_pred))\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"{accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a89500",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.00005, rho=0.8, epsilon=None, decay=0.0)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bbeed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnhistory = model.fit(X_train_cnn, y_train, batch_size=16, epochs=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bde4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_cnn)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_cnn, y_test)\n",
    "print(f\"{accuracy*100}%\")\n",
    "print(f\"{loss}\")\n",
    "\n",
    "\n",
    "print(np.shape(y_pred))\n",
    "#y_pred = y_pred[:,0:8]\n",
    "print(np.shape(y_pred))\n",
    "y_pred = np.argmax(y_pred,1)\n",
    "\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc8089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ef530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf414c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = make_pipeline(RobustScaler(), LogisticRegression(tol=0.00001, max_iter=10000))\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eac79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = make_pipeline(RobustScaler(), KNeighborsClassifier(n_neighbors = 8))\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187562fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d43f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import glob \n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "# import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "# import optuna\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b40a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "    \"\"\"Function Extracts Features from WAV file\"\"\"\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft=np.abs(librosa.stft(X))\n",
    "    result=np.array([])\n",
    "    mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    result=np.hstack((result, mfccs))\n",
    "    chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    result=np.hstack((result, chroma))\n",
    "    mel=np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T,axis=0)\n",
    "    result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e6f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {\n",
    "    \"angry\" : 0,\n",
    "    \"calm\" : 1,\n",
    "    \"disgust\" : 2,\n",
    "    \"fearful\" : 3,\n",
    "    \"happy\" : 4,\n",
    "    \"neutral\" : 5,\n",
    "    \"sad\" : 6,\n",
    "    \"surprised\" : 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ddd371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    \n",
    "    directory = os.path.join(os.getcwd(),'elec-378-sp2023-speech-emotion-classification/data/data/')\n",
    "\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        file = os.path.join(directory, filename)\n",
    "\n",
    "        emotion=emotions[filename[:len(filename)-7]]\n",
    "        feature=extract_feature(file)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b81b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e33a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print((X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffde0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(threshold=np.inf)\n",
    "print(np.shape(X_test))\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Features extracted: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac26413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_params = {'activation': 'relu', \n",
    "              'solver': 'lbfgs', \n",
    "              'hidden_layer_sizes': 1283, \n",
    "              'alpha': 0.3849485717707319, \n",
    "              'batch_size': 163, \n",
    "              'learning_rate': 'constant',\n",
    "              'max_iter':1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace5084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_model = MLPClassifier(**mlp_params)\n",
    "# clf_model.fit(X_train, y_train)\n",
    "# y_pred = clf_model.predict(X_test)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "scaler = StandardScaler().fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = MLPClassifier(**mlp_params)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(y_pred)\n",
    "print(f\"{accuracy*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "v4_params = {'estimators':[('mlp', models['mlp']), \n",
    "                          ('xgb', models['xgb'])], \n",
    "            'voting':'soft'}\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "scaler = StandardScaler().fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf = make_pipeline(RobustScaler(), VotingClassifier(**v4_params))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf_model.predict(X_test)\n",
    "\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(y_pred)\n",
    "print(f\"{accuracy*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b29847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf085a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67412a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3e8fc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n",
      "22050\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)):\n\u001b[1;32m     39\u001b[0m     file \u001b[38;5;241m=\u001b[39m directory \u001b[38;5;241m+\u001b[39m data[i][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 40\u001b[0m     X[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmake_mfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_mfcc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     y[i] \u001b[38;5;241m=\u001b[39m data[i][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     43\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X\n",
      "Cell \u001b[0;32mIn[8], line 28\u001b[0m, in \u001b[0;36mmake_mfcc\u001b[0;34m(file, n_mfcc)\u001b[0m\n\u001b[1;32m     26\u001b[0m sig, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(sr)\n\u001b[0;32m---> 28\u001b[0m sig_mfcc \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_mfcc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhtk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m sig_mfcc_avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(sig_mfcc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sig_mfcc_avg\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/librosa/feature/spectral.py:2002\u001b[0m, in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;124;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[1;32m   1856\u001b[0m \n\u001b[1;32m   1857\u001b[0m \u001b[38;5;124;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[38;5;124;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2001\u001b[0m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[0;32m-> 2002\u001b[0m     S \u001b[38;5;241m=\u001b[39m power_to_db(\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2004\u001b[0m M: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mfftpack\u001b[38;5;241m.\u001b[39mdct(S, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mdct_type, norm\u001b[38;5;241m=\u001b[39mnorm)[\n\u001b[1;32m   2005\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :n_mfcc, :\n\u001b[1;32m   2006\u001b[0m ]\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lifter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2009\u001b[0m     \u001b[38;5;66;03m# shape lifter for broadcasting\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/librosa/feature/spectral.py:2144\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmelspectrogram\u001b[39m(\n\u001b[1;32m   2022\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   2023\u001b[0m     y: Optional[np\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2033\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   2034\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   2035\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute a mel-scaled spectrogram.\u001b[39;00m\n\u001b[1;32m   2036\u001b[0m \n\u001b[1;32m   2037\u001b[0m \u001b[38;5;124;03m    If a spectrogram input ``S`` is provided, then it is mapped directly onto\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2141\u001b[0m \u001b[38;5;124;03m    >>> ax.set(title='Mel-frequency spectrogram')\u001b[39;00m\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2144\u001b[0m     S, n_fft \u001b[38;5;241m=\u001b[39m \u001b[43m_spectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2145\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2156\u001b[0m     \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[1;32m   2157\u001b[0m     mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/librosa/core/spectrum.py:2838\u001b[0m, in \u001b[0;36m_spectrogram\u001b[0;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[1;32m   2832\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2833\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[1;32m   2834\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput signal must be provided to compute a spectrogram\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2835\u001b[0m         )\n\u001b[1;32m   2836\u001b[0m     S \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2837\u001b[0m         np\u001b[38;5;241m.\u001b[39mabs(\n\u001b[0;32m-> 2838\u001b[0m             \u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2839\u001b[0m \u001b[43m                \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2840\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2841\u001b[0m \u001b[43m                \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2842\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2843\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2844\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2845\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2846\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2847\u001b[0m         )\n\u001b[1;32m   2848\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m power\n\u001b[1;32m   2849\u001b[0m     )\n\u001b[1;32m   2851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m S, n_fft\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/librosa/core/spectrum.py:378\u001b[0m, in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bl_s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, y_frames\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], n_columns):\n\u001b[1;32m    375\u001b[0m     bl_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(bl_s \u001b[38;5;241m+\u001b[39m n_columns, y_frames\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    377\u001b[0m     stft_matrix[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, bl_s \u001b[38;5;241m+\u001b[39m off_start : bl_t \u001b[38;5;241m+\u001b[39m off_start] \u001b[38;5;241m=\u001b[39m fft\u001b[38;5;241m.\u001b[39mrfft(\n\u001b[0;32m--> 378\u001b[0m         \u001b[43mfft_window\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbl_s\u001b[49m\u001b[43m:\u001b[49m\u001b[43mbl_t\u001b[49m\u001b[43m]\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    379\u001b[0m     )\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stft_matrix\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "directory = os.path.join(os.getcwd(),'elec-378-sp2023-speech-emotion-classification/data/data/')\n",
    "data = np.empty((1125, 2), dtype=object)\n",
    "\n",
    "emotion_to_id = {\n",
    "    \"angry\" : 0,\n",
    "    \"calm\" : 1,\n",
    "    \"disgust\" : 2,\n",
    "    \"fearful\" : 3,\n",
    "    \"happy\" : 4,\n",
    "    \"neutral\" : 5,\n",
    "    \"sad\" : 6,\n",
    "    \"surprised\" : 7\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "\n",
    "    if os.path.isfile(f):\n",
    "        emotion = filename[:len(filename)-7]\n",
    "        data[i][0] = \"/\"+filename\n",
    "        data[i][1] = int(emotion_to_id[emotion])\n",
    "        i += 1\n",
    "\n",
    "def make_mfcc(file, n_mfcc):\n",
    "    sig, sr = librosa.load(file)\n",
    "    print(sr)\n",
    "    sig_mfcc = librosa.feature.mfcc(y=sig, sr=sr, n_mfcc=n_mfcc, S=None, htk=True)\n",
    "    sig_mfcc_avg = np.mean(sig_mfcc, axis=1)\n",
    "\n",
    "    return sig_mfcc_avg\n",
    "\n",
    "n_mfcc = 38\n",
    "\n",
    "X = np.empty((len(data), n_mfcc), dtype=float)\n",
    "y = np.empty((len(data)), dtype=int)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    file = directory + data[i][0]\n",
    "    X[i] = make_mfcc(file, n_mfcc=n_mfcc)\n",
    "    y[i] = data[i][1]\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc4ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(os.getcwd(),'elec-378-sp2023-speech-emotion-classification/test/test/')\n",
    "data = np.empty((315, 2), dtype=object)\n",
    "\n",
    "emotion_to_id = {\n",
    "    \"angry\" : 0,\n",
    "    \"calm\" : 1,\n",
    "    \"disgust\" : 2,\n",
    "    \"fearful\" : 3,\n",
    "    \"happy\" : 4,\n",
    "    \"neutral\" : 5,\n",
    "    \"sad\" : 6,\n",
    "    \"surprised\" : 7\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "\n",
    "    if os.path.isfile(f):\n",
    "        data[i][0] = \"/\"+filename\n",
    "        i += 1\n",
    "\n",
    "def make_mfcc(file, n_mfcc):\n",
    "    sig, sr = librosa.load(file)\n",
    "    sig_mfcc = librosa.feature.mfcc(y=sig, sr=sr, n_mfcc=n_mfcc, S=None, htk=True)\n",
    "    sig_mfcc_avg = np.mean(sig_mfcc, axis=1)\n",
    "\n",
    "    return sig_mfcc_avg\n",
    "\n",
    "n_mfcc = 38\n",
    "\n",
    "X = np.empty((len(data), n_mfcc), dtype=float)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    file = directory + data[i][0]\n",
    "    X[i] = make_mfcc(file, n_mfcc=n_mfcc)\n",
    "\n",
    "X_test = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ad2527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = make_pipeline(RobustScaler(), SVC(C=20, tol=0.001))\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"n_mfcc: {n_mfcc}, acc: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a1571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e627389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 3 0 1 3 1 5 7 0 3 7 1 3 0 4 0 0 1 0 3 7 3 0 7 4 7 3 1 3 6 3 2 6 0 7 5\n",
      " 3 2 0 1 1 5 3 3 7 7 3 0 2 0 3 7 7 0 3 2 1 3 3 1 1 2 0 0 3 0 5 3 7 1 3 4 4\n",
      " 6 0 1 3 1 1 3 0 4 7 2 6 4 1 6 2 2 4 0 1 0 3 0 5 2 6 6 1 4 2 6 6 1 6 4 6 1\n",
      " 3 7 6 0 7 7 3 4 3 7 6 2 4 5 2 3 2 3 3 7 2 0 5 6 3 5 1 1 0 7 6 6 4 1 6 1 5\n",
      " 1 3 3 1 3 2 6 4 1 6 2 2 2 7 2 7 0 7 5 7 4 6 0 7 2 0 0 1 6 3 5 7 7 3 3 0 0\n",
      " 6 3 2 6 4 1 1 2 2 1 1 7 3 6 7 2 0 5 6 7 0 6 4 0 0 3 7 0 1 3 1 6 6 4 3 0 6\n",
      " 7 6 1 4 1 6 1 2 7 1 1 4 5 2 6 0 1 4 7 0 2 1 3 4 6 1 7 6 1 3 1 4 7 2 3 2 1\n",
      " 1 0 0 6 3 7 7 4 0 4 0 7 3 3 3 1 3 2 7 7 4 2 4 6 0 0 4 7 3 5 0 1 6 1 4 1 4\n",
      " 2 3 3 0 6 5 1 6 5 7 0 7 0 7 4 7 7 6 5]\n",
      "['happy', 'happy', 'fearful', 'angry', 'calm', 'fearful', 'calm', 'neutral', 'surprised', 'angry', 'fearful', 'surprised', 'calm', 'fearful', 'angry', 'happy', 'angry', 'angry', 'calm', 'angry', 'fearful', 'surprised', 'fearful', 'angry', 'surprised', 'happy', 'surprised', 'fearful', 'calm', 'fearful', 'sad', 'fearful', 'disgust', 'sad', 'angry', 'surprised', 'neutral', 'fearful', 'disgust', 'angry', 'calm', 'calm', 'neutral', 'fearful', 'fearful', 'surprised', 'surprised', 'fearful', 'angry', 'disgust', 'angry', 'fearful', 'surprised', 'surprised', 'angry', 'fearful', 'disgust', 'calm', 'fearful', 'fearful', 'calm', 'calm', 'disgust', 'angry', 'angry', 'fearful', 'angry', 'neutral', 'fearful', 'surprised', 'calm', 'fearful', 'happy', 'happy', 'sad', 'angry', 'calm', 'fearful', 'calm', 'calm', 'fearful', 'angry', 'happy', 'surprised', 'disgust', 'sad', 'happy', 'calm', 'sad', 'disgust', 'disgust', 'happy', 'angry', 'calm', 'angry', 'fearful', 'angry', 'neutral', 'disgust', 'sad', 'sad', 'calm', 'happy', 'disgust', 'sad', 'sad', 'calm', 'sad', 'happy', 'sad', 'calm', 'fearful', 'surprised', 'sad', 'angry', 'surprised', 'surprised', 'fearful', 'happy', 'fearful', 'surprised', 'sad', 'disgust', 'happy', 'neutral', 'disgust', 'fearful', 'disgust', 'fearful', 'fearful', 'surprised', 'disgust', 'angry', 'neutral', 'sad', 'fearful', 'neutral', 'calm', 'calm', 'angry', 'surprised', 'sad', 'sad', 'happy', 'calm', 'sad', 'calm', 'neutral', 'calm', 'fearful', 'fearful', 'calm', 'fearful', 'disgust', 'sad', 'happy', 'calm', 'sad', 'disgust', 'disgust', 'disgust', 'surprised', 'disgust', 'surprised', 'angry', 'surprised', 'neutral', 'surprised', 'happy', 'sad', 'angry', 'surprised', 'disgust', 'angry', 'angry', 'calm', 'sad', 'fearful', 'neutral', 'surprised', 'surprised', 'fearful', 'fearful', 'angry', 'angry', 'sad', 'fearful', 'disgust', 'sad', 'happy', 'calm', 'calm', 'disgust', 'disgust', 'calm', 'calm', 'surprised', 'fearful', 'sad', 'surprised', 'disgust', 'angry', 'neutral', 'sad', 'surprised', 'angry', 'sad', 'happy', 'angry', 'angry', 'fearful', 'surprised', 'angry', 'calm', 'fearful', 'calm', 'sad', 'sad', 'happy', 'fearful', 'angry', 'sad', 'surprised', 'sad', 'calm', 'happy', 'calm', 'sad', 'calm', 'disgust', 'surprised', 'calm', 'calm', 'happy', 'neutral', 'disgust', 'sad', 'angry', 'calm', 'happy', 'surprised', 'angry', 'disgust', 'calm', 'fearful', 'happy', 'sad', 'calm', 'surprised', 'sad', 'calm', 'fearful', 'calm', 'happy', 'surprised', 'disgust', 'fearful', 'disgust', 'calm', 'calm', 'angry', 'angry', 'sad', 'fearful', 'surprised', 'surprised', 'happy', 'angry', 'happy', 'angry', 'surprised', 'fearful', 'fearful', 'fearful', 'calm', 'fearful', 'disgust', 'surprised', 'surprised', 'happy', 'disgust', 'happy', 'sad', 'angry', 'angry', 'happy', 'surprised', 'fearful', 'neutral', 'angry', 'calm', 'sad', 'calm', 'happy', 'calm', 'happy', 'disgust', 'fearful', 'fearful', 'angry', 'sad', 'neutral', 'calm', 'sad', 'neutral', 'surprised', 'angry', 'surprised', 'angry', 'surprised', 'happy', 'surprised', 'surprised', 'sad', 'neutral']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "id_to_emotion = dict((v, k) for k, v in emotion_to_id.items())\n",
    "y_pred = [id_to_emotion[x] for x in y_pred]\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abc71a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4897b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# os.chdir('/content/drive/MyDrive/2022-2023 Semester 2/Elec 378 Final Project')\n",
    "\n",
    "names = [x[1:len(x)-4] for x in data[:,0]]\n",
    "\n",
    "df = pd.DataFrame(list(zip(names, y_pred)), columns=['filename', 'label'])\n",
    "df.to_csv(\"y_kaggle_svm16.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac62bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f35079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
